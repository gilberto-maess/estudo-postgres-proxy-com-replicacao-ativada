# Arquitetura de Alta Disponibilidade ‚Äî Keycloak 26+

## üìò Vis√£o Geral

A partir da vers√£o **26**, o **Keycloak** passou a manter as **sess√µes de usu√°rio no banco de dados**, eliminando a depend√™ncia de cache distribu√≠do (como Infinispan) para persist√™ncia de sess√£o.  
Isso simplifica a arquitetura de alta disponibilidade (HA) e torna poss√≠vel escalar horizontalmente os pods do Keycloak sem perder sess√µes.

Essa mudan√ßa √© fundamental para a **infraestrutura da Docway**, pois permite alta disponibilidade e resili√™ncia com menor complexidade de configura√ß√£o.

---

## ‚öôÔ∏è Topologia Recomendada

O **Keycloak** deve ser implantado em um **cluster Kubernetes** com:

- **M√≠nimo:** 2 r√©plicas (para garantir disponibilidade)
- **M√°ximo:** 5 r√©plicas (via HPA - Horizontal Pod Autoscaler)
- **Banco de dados externo** (em outro cluster ou servi√ßo dedicado)
- **Monitoramento cont√≠nuo** de desempenho e consumo de recursos

### Benef√≠cio da nova arquitetura

Como as sess√µes est√£o no banco de dados, a perda de um pod n√£o invalida as sess√µes ativas.  
Isso significa que o HPA pode escalar os pods (para cima ou para baixo) sem desconectar usu√°rios.

---

## üìà Escalabilidade e Disponibilidade

| Componente | Tipo de Escala | Impacto Principal | Observa√ß√µes |
|-------------|----------------|------------------|--------------|
| **Keycloak (Pods)** | Horizontal | Disponibilidade | M√∫ltiplas r√©plicas garantem redund√¢ncia. Sess√µes persistem no banco. |
| **Banco de Dados** | Vertical / Horizontal | Performance | Aumentar CPU, mem√≥ria e IOPS melhora tempo de resposta. |

> ‚ö†Ô∏è **Importante:** o aumento no n√∫mero de r√©plicas do Keycloak **n√£o melhora a performance** da autentica√ß√£o em si, mas garante continuidade do servi√ßo em caso de falhas.

---

## üîç Monitoramento e Observabilidade

Deve ser implementado monitoramento cont√≠nuo de:
- Uso de CPU e mem√≥ria dos pods
- M√©tricas de resposta e lat√™ncia (Keycloak)
- Conex√µes e tempo de resposta do banco de dados
- Triggers de autoescalonamento (HPA)
- Logs centralizados (Prometheus + Grafana ou similar)

Esses dados devem orientar ajustes peri√≥dicos nos limites de recursos e regras de escalabilidade.

---

## ‚ö° Melhoria de Performance

Para melhorar o desempenho, as seguintes a√ß√µes s√£o recomendadas:

1. **Aumentar recursos do cluster:**
   - Mais CPU e mem√≥ria por n√≥
   - Armazenamento SSD com alta taxa de IOPS

2. **Reduzir lat√™ncia geogr√°fica:**
   - Manter **Keycloak, banco de dados e aplica√ß√µes na mesma regi√£o geogr√°fica**
   - Prefer√™ncia por **datacenters no Brasil** para usu√°rios locais

3. **Escalar o banco de dados:**
   - **Verticalmente:** mais CPU, mem√≥ria e IOPS
   - **Horizontalmente:** adicionar r√©plicas de leitura

---

## üóÑÔ∏è Estrutura do Banco de Dados

Existem duas abordagens poss√≠veis para o banco de dados PostgreSQL usado pelo Keycloak:

### ‚òÅÔ∏è Cloud (Google Cloud SQL)

- Inst√¢ncia gerenciada com r√©plicas de leitura opcionais
- Custo de cada r√©plica equivale ao custo do master
- HA dobra o custo (r√©plica s√≠ncrona em outra zona)
- Custo adicional com **sa√≠da de rede** entre zonas
- Simplifica o gerenciamento (backup, patch, failover autom√°tico)

### üè¢ On-Premises

#### Requisitos:

- **Proxy L4 (TCP)** ‚Äî recomendado **HAProxy**
- **1 banco master** (escrita)
- **1 ou mais bancos de leitura**

#### Fluxo de Escrita e Leitura:

- Todas as **escritas** v√£o para o **master**
- O **master replica** os dados para os bancos de leitura
- Se o **master cair**, as leituras continuam funcionando, mas as escritas falham at√© a recupera√ß√£o
- Se cair um banco de leitura, n√£o h√° impacto na disponibilidade geral

#### Benef√≠cio:

O Keycloak aponta para o **host do HAProxy**, que distribui as conex√µes de forma transparente, garantindo:
- Alta disponibilidade
- Failover simplificado
- Compatibilidade com m√∫ltiplas r√©plicas de Keycloak e de banco

---

## üß≠ Diagrama da Arquitetura

```mermaid
flowchart LR
  subgraph K8S[Cluster Kubernetes - Keycloak]
    subgraph Deploy[Deployment: Keycloak]
      K1[Pod: keycloak-0]
      K2[Pod: keycloak-1]
      K3[Pod: keycloak-2]
    end

    SVC[Service: keycloak - ClusterIP]
    HPA{{HPA: 2-5 replicas}}
    ING[Ingress Controller NGINX + TLS]
  end

  subgraph DB[Cluster Banco de Dados]
    HA[HAProxy TCP Proxy]
    M[(PostgreSQL Master)]
    R1[(Replica de Leitura 1)]
    R2[(Replica de Leitura 2)]
  end

  Users[Usu√°rios / Aplica√ß√µes] -->|HTTPS| ING
  ING -->|Rota /auth| SVC
  SVC --> K1
  SVC --> K2
  SVC --> K3
  HPA -.controla.-> Deploy
  K1 -->|SQL| HA
  K2 -->|SQL| HA
  K3 -->|SQL| HA
  HA --> M
  HA --> R1
  HA --> R2
```

---

## üß≠ Aplica√ß√£o

> Os scripts abaixo foram aplicados no WSL2 usando a distro Ubuntu.

### Docker Compose:

```yml
services:

  pg1:
    image: postgres:16
    container_name: pg1
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: senha123
      POSTGRES_DB: appdb
    volumes:
      - pg1_data:/var/lib/postgresql/data
      - ./init-primary.sh:/docker-entrypoint-initdb.d/init-primary.sh:ro

  pg2:
    image: postgres:16
    container_name: pg2
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: senha123
      POSTGRES_DB: appdb
    restart: always
    volumes:
      - pg2_data:/var/lib/postgresql/data
      - ./init-replica.sh:/docker-entrypoint-initdb.d/init-replica.sh:ro

  pg3:
    image: postgres:16
    container_name: pg3
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: senha123
      POSTGRES_DB: appdb
    restart: always
    volumes:
      - pg3_data:/var/lib/postgresql/data
      - ./init-replica.sh:/docker-entrypoint-initdb.d/init-replica.sh:ro

  haproxy:
    image: haproxy:2.9
    container_name: haproxy
    ports:
      - "6432:6432"
      - "8404:8404"
    volumes:
      - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro

volumes:
  pg1_data:
  pg2_data:
  pg3_data:
```

### haproxy.cfg

```cfg
global
    maxconn 200

defaults
    log global
    mode tcp
    timeout connect 10s
    timeout client 1m
    timeout server 1m

frontend postgresql
    bind *:6432
    default_backend pg_cluster

backend pg_cluster
    mode tcp
    balance roundrobin
    option tcp-check
    server pg1 pg1:5432 check
    server pg2 pg2:5432 check backup
    server pg3 pg3:5432 check backup

listen stats
    bind *:8404
    mode http
    stats enable
    stats uri /
    stats refresh 5s
```

### init-primary.sh

```bash
#!/bin/bash
set -e
echo "Configuring primary (pg1)..."

cat >> /var/lib/postgresql/data/postgresql.conf <<EOF
wal_level = replica
max_wal_senders = 10
wal_keep_size = 64
listen_addresses = '*'
EOF

cat >> /var/lib/postgresql/data/pg_hba.conf <<EOF
host replication replicator all md5
host all all all md5
EOF

psql -U postgres -c "CREATE ROLE replicator WITH REPLICATION LOGIN PASSWORD 'replica123';"
echo "Primary setup complete."
```

### init-replica.sh

```bash
#!/bin/bash
set -e
echo "Configuring replica..."
sleep 10
rm -rf /var/lib/postgresql/data/*

PGPASSWORD=replica123 pg_basebackup -h pg1 -D /var/lib/postgresql/data -U replicator -Fp -Xs -P -R

echo "Replica setup complete."

```

### Levantando o ambiente:

```sh
docker compose up
```

### Testando o proxy:

```sh

# Aten√ß√£o: Execute linha a linha. N√£o execute todo o script abaixo de uma s√≥ vez.

# 1) Instala√ß√£o do client do postgres
sudo apt install postgresql-client-common postgresql-client
psql --version

# 2) Teste de proxy + replica√ß√£o
# Conectando no server (senha -> senha123)
psql -h localhost -p 6432 -U postgres -d appdb
# Note aque estamos nos conectando no host do HAproxy.
# Se voc√™ se conectou, significa que o proxy est√° funcionando.

# Cria√ß√£o de tabela + inser√ß√£o de dado pra teste
CREATE TABLE teste (id serial PRIMARY KEY, nome text);
INSERT INTO teste (nome) VALUES ('Replica funcionando!');
# Toda opera√ß√£o de escrita √© realizada no n√≥ master, ou seja, pg1

# 3) Testando a replica√ß√£o
docker exec -it pg2 psql -U postgres -d appdb -c "SELECT * FROM teste;" # teste no primeiro n√≥ de replica√ß√£o, o pg2
docker exec -it pg3 psql -U postgres -d appdb -c "SELECT * FROM teste;" # teste no segundo n√≥ de replica√ß√£o, o pg3

# Se voc√™ conseguiu consultar a tabela "teste" com uma linha com o valor "Replica funcionando!" em cada um dos n√≥s de replica√ß√£o, ent√£o a replica√ß√£o est√° funcionando.
```

---

‚úÖ Conclus√£o

Com o Keycloak 26+, a alta disponibilidade torna-se mais simples e robusta, j√° que:

- Sess√µes est√£o centralizadas no banco de dados;
- R√©plicas de aplica√ß√£o podem escalar livremente;
- O uso de proxy e r√©plicas de banco garante resili√™ncia e continuidade.

A arquitetura proposta assegura alta disponibilidade, resili√™ncia a falhas, e possibilidade de evolu√ß√£o gradual ‚Äî tanto em infraestrutura quanto em escala de usu√°rios.

---
Respons√°vel t√©cnico: Gilberto Ferreira

Projeto: Docway ‚Äî Infraestrutura de Autentica√ß√£o

Vers√£o: 1.0

Data: 2025-10-06